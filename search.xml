<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>又日新-2025Jan</title>
    <url>/2025/01/03/diary/2025jan/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="wrong password" data-whm="抱歉, 这个文章不能被校验, 不过您还是能看看解密后的内容.">
  <script id="hbeData" type="hbeData" data-hmacdigest="f80d4eeb1fbee217ba01c234e209776ac5468f865e0d15d51c7d66eb00a5cde7">226ddbb6d87d935d995eb2cfacee44c3b04ce12ecd979cc1732b8ca32f36c7713f267bffbf4f57c997c86cf464506094a980c4c8db56311b3fbcf4e725038f4d4a54542fcd254f2546ae18eb5e6c51d1a0e562cd8962031f55f74ec9568bf08dcc3b23bcb0d6969c314a6370e578bf091b3e9255e813a215bb4f17ba08b9737808d93c5a692f122b224230706960bda55e514b51c04de746ff1e061028b7350733b548c941478ac8c350d555f99b915ba0db83042a3da92c9379ac67eff92dc613298e3d62bf5dcdf5ddf8e2a4389cf7ef6524ae6d723976001ed1968e6dd9c6d61e123e3f5574f61daec5868cb0ba506b6bf93a7f2e7ca48ebe354fd5de5ac70eec7891070f9edc94e0fb29d40fb30840f3e60fece9904a8fd4a8f23ec8375f57f63d6d5f66e375153ad3352daaa451cef7bb105e152ab2ec80373e2c8c23e2eb6c93b15a22c0da4e576fce0a4132d0522c2d4f272a4864bde19a47467462f5b8db611a450181bf37015feeec2c368142f4af9e90e9771e48d9146217fa51123e44395edfed48dc01d5cdd2b488bb6a21379887d9b9e6b8a0c3c4ce9453c8ecc45b345fc29916c300df76959d6e69e386b1e16b16f1ba9ec376a3e38466374c0e4e3e5738de70230b5a3ef04d904dbd7b71fcb82b357c44fa81384ad2d4fc8e7b47f01e411841256a323415fbfa1cb3bdfe52be99c66c2e4aa3da76921dddeb645a0829ba5453f2ef61c3698ad111858433b3ede13f46ea162e653e8b0c7fe530821731a60592fb72c71fd43d2db26a772575ceeb675ebb7e04d675c53d06eb5809ba3f127411012b13ea7c1cbb3169b61e48c92fea11c6be256d97f71deb50fb12df5e6744bc83576342f8831553ba76fbe0554a34f32534a69cd54e2edb4745c36c4736f13560a78e02c62c8cfc30221824309d2d868407c91cd4a277dc5d57a5f0b402c34087847172c5f85328537a85079d6c81f810572ff13113b3747854568ed2c3b84849c281c1cb87d0964ddebada5750decb2cfc96c933a41a7a947032ed4705591666cca9882b276f8c9fd199a461422665aef67763e6c9cf8bc1b5831d0ff0e23ef55882531424e1328f3228640049832688fd08f8166ef1884d6692a862bda3e3e84799c2cc91d3d59b7a7809d2e029389965578f36981e4e8bc5b5e021eeff03b373cdb604d00d78af532db439f7740e113cc9a3b0794d59771b8cd1c3443698e33beb0b76104248ec396fa78e44287c88005ac8dd28abe71cec625460558327b369fc0eb41463d204937a21b301a9e53a17622b9bf1a1dc89efa9d56450b00dd0378f5db94412c98d311e81a198b06b8417edfad850502976e00d4e9a9a127020feefcabe4693dca2f56926ed8a84f6aba1ec29b5d2d15d1d1b75bb9647539f320a40ae2ff00451cf8f3f2d9ea50ad9b8137a0007ad93ce77ea67741130291dd204c9f8068dcb9f05f5b4ecc66fae38bc6a6c98e26cca7347d36cecef6cb964a708307a271a29830acc4fff8ffe2cbbcc2c6b0bd379d8579e7b4e66e764e884910d0c1fb35acbd72877ebfead542e21fe2240bd846b93ad7172a47b6a00494015dd9f91fcad7d9b340ba68524c1b97abcc91c269069e2a08dd1d217f24914bcc6f1c186b16d91dfb61f7700680c472c7b4ddb1378807f369f9632db02a0e0ac5e2c2fb3163bc4bdaaa7ff3c41292a8f838401816b0348582ebcd5125d51d0f9509b0c84a3fbdd7c3ed3d993fad89c902c42838d83592796ce3fca249daedf6f2d506f1f60d043c44fe585e669c338f5148b9e19fba44dbee74485c8cae2bd6ab2558e1e5087b3a89139baba69c3dbb7141ef95056bbdc493c2f44e2d7a94bbc408409e2e233806c8b7dd458ccac87aa9be7c33ed61867b7b77d697c31057378569ed16507bebbbea36237083f392fa7d6bbaf21e24760e1dd4cbc41f2f33187715fb609d5fb17ceed5d66da81a110bd556318a86d98afb99c87f0f6a0bf0b4019f30b87ce994a1c80bfd0c2bd92f89de9453dec67849a919595d2b0a7d9f8f0c690728944b76a44ff47c85ad5dc4621a96be5fd0a694de6c6dc438bfe3ca4af050115b054906f0655dab0ef0ed6ead1c4da514989c96d04f5e018e0894dfa5608257d3e15072d0d8e51e42a625db9e505cdfce2b0d632f618142d153548fe2f18fc20a414b77b21f07cdd238664973609557d2fe0d323232fcfb5bf7c9b990fffa7726e0c55e0ac051ce992038595683619fc5ce736f5f15a2019e51257fefdaec27a3a220d155597b81d0119aef07cee27bc999c99b77b62524e538ff12aa93fcd796b7e24f8f85a958266670ada0b0d66929c374157033b22ca074c846aec83dae480bb1f833a26197584daf6c97e78108eb84baffa2f5b1b050d29d09478010f15d40f458dd5a616acce488026515de91fe8daa615f61d3b3b4255481003132d00c09dc0ecadb64944cb8c40d0fa81673fcf73d6e5911c30da8b53ddc1cb06750a0c894d83fadb</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-default">
      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-default">enter password...</span>
      </label>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>采薇</category>
        <category>又日新</category>
      </categories>
      <tags>
        <tag>日记</tag>
      </tags>
  </entry>
  <entry>
    <title>又日新-2024</title>
    <url>/2024/04/14/diary/2024/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="wrong password" data-whm="抱歉, 这个文章不能被校验, 不过您还是能看看解密后的内容.">
  <script id="hbeData" type="hbeData" data-hmacdigest="b8f6742e55f42e855f0793025bbcdf3b8a5a0846229e0f21eefb2b2f392a28c7">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</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-default">
      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-default">enter password...</span>
      </label>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>采薇</category>
        <category>又日新</category>
      </categories>
      <tags>
        <tag>日记</tag>
      </tags>
  </entry>
  <entry>
    <title>SWS3004-Lecture 4: Cloud Software Development and Deployment</title>
    <url>/2023/08/10/sws3004/lecture4/</url>
    <content><![CDATA[<p>L4 is about Cloud Software Development and Deployment.</p>
<span id="more"></span>
<h2 id="outline">Outline</h2>
<ul>
<li><p>Cloud Software Development</p></li>
<li><p>Learning Objectives</p></li>
<li><p>SaaS is Different from Traditional Software</p></li>
<li><p>Different Perspectives of SaaS Development</p>
<ul>
<li><p>SaaS with Self-managed Infrastructure and Self-managed
Platform</p></li>
<li><p>SaaS with Self-managed Platform</p></li>
<li><p>SaaS with Self-managed Infrastructure</p></li>
<li><p>SaaS with Cloud-enabled IaaS and SaaS</p></li>
</ul></li>
<li><p>Summary</p></li>
</ul>
<h1 id="cloud-software-development">Cloud Software Development</h1>
<ul>
<li><p>Power of cloud computing – exploits higher service-level
abstraction, PaaS and SaaS, to reduce the time and cost of software
development</p></li>
<li><p><strong>SaaS</strong> changes the way software is
<em>delivered</em></p>
<ul>
<li>usage-based billing, high scalability, ease of access, automated
updates</li>
</ul></li>
<li><p><strong>PaaS</strong> changes the way the (SaaS) software is
<em>developed</em></p>
<ul>
<li>automates the process of deployment, testing and scaling to reduce
manual work and cost of application development</li>
</ul></li>
</ul>
<h2 id="learning-objectives">Learning Objectives</h2>
<ol type="1">
<li><p>Understand how SaaS applications are different from traditional
software/application</p></li>
<li><p>Understand the different perspectives of SaaS software
development</p></li>
</ol>
<h1 id="saas-is-different-from-traditional-software">SaaS is Different
from Traditional Software</h1>
<ul>
<li><p><strong>Pay-per-use</strong> - provides web access to commercial
software on pay-as you-use vs traditional pay the full license
fee</p></li>
<li><p><strong>Zero infrastructure</strong> – customers need not install
the software (SaaS developed, deployed and managed by service provider)
vs ASP (application service provider) owns and manages dedicated
infrastructure for each customers</p></li>
<li><p><strong>Reduced business cost</strong> – 1-many - same SaaS
application shared by multiple customers (multi-tenants) vs traditional
1-1 end-users and software relationship</p></li>
<li><p><strong>Automated updates</strong> – Updates performed by service
providers (SaaS) not by users (traditional)</p></li>
</ul>
<h2 id="suitability-of-saas">Suitability of SaaS</h2>
<h3 id="not-suitable">Not suitable</h3>
<ul>
<li><p>Real-time processing where fast processing of data is
needed</p></li>
<li><p>Organization’s data is more confidential and data localization is
needed</p></li>
<li><p>When on-premise applications fulfil organization’s needs</p></li>
</ul>
<h3 id="suitable">Suitable</h3>
<ul>
<li><p>Consumers require on-demand software rather than full
term/licensing-based software</p></li>
<li><p>Start-up company that cannot invest in buying licensed
software</p></li>
<li><p>Applications with unpredictable and dynamic load</p></li>
</ul>
<h1 id="different-perspectives-of-saas-development">Different
Perspectives Of SaaS Development</h1>
<ul>
<li><p>2 key challenges</p>
<ul>
<li><p>choosing correct multitenancy level(s) - multitenancy can be
achieved at different levels such as infrastructure, platform and
application</p></li>
<li><p>governance and security over user data</p></li>
</ul></li>
<li><p>four perspectives</p>
<ul>
<li><p>SaaS with Self-managed Infrastructure and Self-managed
Platform</p></li>
<li><p>SaaS with Self-managed Platform</p></li>
<li><p>SaaS with Self-managed Infrastructure</p></li>
<li><p>SaaS with Cloud-enabled IaaS and PaaS</p></li>
</ul></li>
</ul>
<h2 id="saas-with-self-managed-infrastructure-and-self-managed-platform">SaaS
with Self-managed Infrastructure and Self-managed Platform</h2>
<div style="text-align: center;">
<p><img src="/images/sws3004-lec4/1.png" alt="SaaS with Self-managed Infrastructure and Self-managed Platform" style="width: 90%; height: 90%; display: block; margin: 0 auto;"></p>
</div>
<h2 id="saas-with-self-managed-platform">SaaS with Self-managed
Platform</h2>
<div style="text-align: center;">
<p><img src="/images/sws3004-lec4/2.png" alt="SaaS with Self-managed Platform" style="width: 90%; height: 90%; display: block; margin: 0 auto;"></p>
</div>
<h2 id="saas-with-self-managed-infrastructure">SaaS with Self-managed
Infrastructure</h2>
<div style="text-align: center;">
<p><img src="/images/sws3004-lec4/3.png" alt="SaaS with Self-managed Infrastructure" style="width: 90%; height: 90%; display: block; margin: 0 auto;"></p>
</div>
<h2 id="saas-with-cloud-enabled-iaas-and-paas">SaaS with Cloud-enabled
IaaS and PaaS</h2>
<div style="text-align: center;">
<p><img src="/images/sws3004-lec4/4.png" alt="SaaS with Cloud-enabled IaaS and PaaS" style="width: 90%; height: 90%; display: block; margin: 0 auto;"></p>
</div>
<h1 id="summary">Summary</h1>
<ul>
<li><p>cloud software development</p>
<ul>
<li><p>SaaS changes the way software is delivered</p></li>
<li><p>SaaS is different from traditional software</p></li>
<li><p>SaaS development: from self-managed to cloud enabled IaaS and/or
PaaS</p></li>
</ul></li>
<li><p>cloud-enabled platform services (with advanced capabilities
around artificial intelligence (AI), data analytics, blockchain, IoT, …)
+ server-less computing changes the development, deployment and cost of
more complex software applications</p></li>
</ul>
]]></content>
      <categories>
        <category>云开发</category>
      </categories>
      <tags>
        <tag>Cloud</tag>
      </tags>
  </entry>
  <entry>
    <title>SWS3004-Lecture 3: Big Data Architecture and Patterns</title>
    <url>/2023/08/08/sws3004/lecture3/</url>
    <content><![CDATA[<p>L3 is about Big Data Architecture and Patterns.</p>
<span id="more"></span>
<h2 id="overview">Overview</h2>
<ul>
<li><p>Big Data and Big Data Architectures</p></li>
<li><p>Platforms</p>
<ul>
<li><p>MapReduce, Hadoop, and HDFS</p></li>
<li><p>Spark</p></li>
<li><p>Cloud Dataflow and Beam</p></li>
</ul></li>
</ul>
<h1 id="big-data-and-big-data-architectures">Big Data and Big Data
Architectures</h1>
<h2 id="big-data">Big Data</h2>
<div style="text-align: center;">
<p><img src="/images/sws3004-lec3/1.png" alt="Big Data Characteristics" style="width: 90%; height: 90%; display: block; margin: 0 auto;"></p>
</div>
<h2 id="big-data-architectures">Big Data Architectures</h2>
<div style="text-align: center;">
<p><img src="/images/sws3004-lec3/2.png" alt="Big Data Architectures" style="width: 90%; height: 90%; display: block; margin: 0 auto;"></p>
</div>
<h2 id="big-data-platform-and-applications">Big Data Platform and
Applications</h2>
<ul>
<li><p>Multicore/Cluster era → parallel and distributed
applications</p></li>
<li><p>Parallelism</p>
<ul>
<li><p>Task-parallel</p></li>
<li><p>Data-parallel</p>
<ul>
<li><p>Batch (MapReduce, Spark, Cloud Dataflow)</p></li>
<li><p>Stream (Spark Streaming, Flink, Cloud Dataflow)</p></li>
</ul></li>
<li><p>Mixed</p></li>
</ul></li>
<li><p>System resource demand</p>
<ul>
<li><p>Compute-intensive</p></li>
<li><p>Data-intensive</p></li>
<li><p>Mixed</p></li>
</ul></li>
</ul>
<h1 id="platforms">Platforms</h1>
<h2 id="mapreduce-hadoop-and-hdfs">MapReduce, Hadoop, and HDFS</h2>
<h3 id="mapreduce-programming-model">MapReduce Programming Model</h3>
<ul>
<li><p>Supports arbitrarily divisible workload</p></li>
<li><p>Supports distributed computing on large data sets on multiple
machines (clusters, public or private clouds, …)</p></li>
<li><p>How large an amount of work?</p>
<ul>
<li><p>Web-scale data on the order of 100s of GBs to TBs or PBs</p></li>
<li><p>Input data set will not likely fit on a single computer’s hard
drive</p></li>
<li><p>Distributed file system (e.g., Google File System- GFS) is
typically required</p></li>
</ul></li>
<li><p>Inspired by the <strong>map</strong> and <strong>reduce</strong>
functions in functional programming languages</p></li>
<li><p><strong>Key idea</strong></p>
<ul>
<li><strong>Split</strong> data into blocks and assign each block to an
instance/process for parallel execution</li>
<li><strong>Merge</strong> partial results produced by individual
instances after all instances completed execution</li>
</ul></li>
<li><p>Transform a set of <strong>input &lt;key, value&gt;</strong>
pairs into a set of <strong>output &lt;key, value&gt;</strong>
pairs</p></li>
<li><p><strong>SPMD (Same Program Multiple Data)</strong> - a master
instance partitions the data and gathers the partial results</p></li>
</ul>
<h4 id="structure-of-a-mapreduce-program">Structure of a MapReduce
Program</h4>
<ol type="1">
<li><p>Read (a lot of) data</p></li>
<li><p><strong>MAP</strong> (extract data you need from each
record)</p></li>
<li><p>Shuffle and Sort data</p></li>
<li><p><strong>REDUCE</strong> (aggregate, summarize, filter, transform
extracted data)</p></li>
<li><p>Write the results</p></li>
</ol>
<div style="text-align: center;">
<p><img src="/images/sws3004-lec3/3.png" alt="MapReduce" style="width: 90%; height: 90%; display: block; margin: 0 auto;"></p>
</div>
<div style="text-align: center;">
<p><img src="/images/sws3004-lec3/4.png" alt="High-level View of MapReduce" style="width: 90%; height: 90%; display: block; margin: 0 auto;"></p>
</div>
<div style="text-align: center;">
<p><img src="/images/sws3004-lec3/5.png" alt="MapReduce Execution" style="width: 90%; height: 90%; display: block; margin: 0 auto;"></p>
</div>
<div style="text-align: center;">
<p><img src="/images/sws3004-lec3/6.png" alt="Parallelism in MapReduce" style="width: 90%; height: 90%; display: block; margin: 0 auto;"></p>
</div>
<h3 id="hadoop">Hadoop</h3>
<ul>
<li><p><strong>Google MapReduce</strong> - <strong>closed</strong>
source developed by Google (2004) to process large amounts of raw
data</p></li>
<li><p><strong>Hadoop MapReduce</strong> – <strong>open</strong> source
developed by Apache + Yahoo (Java programming language) – a popular
implementation of MapReduce</p></li>
<li><p>Presents MapReduce as an analytics engine with a distributed
storage layer referred to as Hadoop Distributed File System
(<em>HDFS</em>); HDFS mimics Google File System (<em>GFS</em>)</p></li>
<li><p>Example: Amazon Elastic MapReduce creates a Hadoop cluster and
handles data transfers between Amazon EC2 (computation) and Amazon S3
(storage)</p></li>
</ul>
<div style="text-align: center;">
<p><img src="/images/sws3004-lec3/7.png" alt="Hadoop Architecture" style="width: 90%; height: 90%; display: block; margin: 0 auto;"></p>
</div>
<div style="text-align: center;">
<p><img src="/images/sws3004-lec3/8.png" alt="Hadoop on Multi-node" style="width: 90%; height: 90%; display: block; margin: 0 auto;"></p>
</div>
<div style="text-align: center;">
<p><img src="/images/sws3004-lec3/9.png" alt="Hadoop Distributed File System" style="width: 90%; height: 90%; display: block; margin: 0 auto;"></p>
</div>
<h2 id="spark">Spark</h2>
<h3 id="apache-spark">Apache Spark</h3>
<ul>
<li><p>Distributed processing framework and programming model for big
data workloads</p></li>
<li><p>Utilizes in-memory caching, and optimized query execution for
fast analytic queries against data of any size</p></li>
<li><p>It provides development APIs in Java, Scala, Python and R, and
supports code reuse across multiple workloads:</p>
<ul>
<li><p>Batch processing</p></li>
<li><p>Machine Learning</p></li>
<li><p>Interactive queries</p></li>
<li><p>Real-time analytics</p></li>
</ul></li>
</ul>
<div style="text-align: center;">
<p><img src="/images/sws3004-lec3/10.png" alt="Apache Spark" style="width: 90%; height: 90%; display: block; margin: 0 auto;"></p>
</div>
<h3 id="spark-rdd">Spark RDD</h3>
<ul>
<li><p>Main abstraction: <strong>resilient distributed dataset
(RDD)</strong> - a collection of elements partitioned across the nodes
of the cluster that can be operated on in parallel.</p></li>
<li><p>RDD - created from the file system or through operations
(transformations)</p></li>
<li><p>Option to <em>persist</em> an RDD in memory or on disk to be
reused efficiently across parallel operations</p></li>
<li><p>RDD used for fault tolerance: recover from node failures</p></li>
</ul>
<div style="text-align: center;">
<p><img src="/images/sws3004-lec3/11.png" alt="Spark Execution" style="width: 90%; height: 90%; display: block; margin: 0 auto;"></p>
</div>
<h2 id="cloud-dataflow-and-beam">Cloud Dataflow and Beam</h2>
<h3 id="google-cloud-dataflow">Google Cloud Dataflow</h3>
<p>“<strong>The Dataflow Model</strong>: A Practical Approach to
Balancing Correctness, Latency, and Cost in Massive-Scale, Unbounded,
Out-of-Order Data Processing"</p>
<p><a href="https://research.google.com/pubs/archive/43864.pdf">reference</a></p>
<h3 id="apache-beam">Apache Beam</h3>
<ul>
<li><p>Parallel computing framework for data processing</p></li>
<li><p>Multiple SDKs (Java, Python, Go, Scala)</p></li>
<li><p>Unified data model (PCollection):</p>
<ul>
<li>batch (bounded)</li>
<li>streaming (unbounded)</li>
</ul></li>
<li><p>Pipelines containing data processing operations (PTransform)</p>
<ul>
<li><p>Source transforms</p></li>
<li><p>Processing and Conversion transforms (Count, Sum, Map,
GroupBy)</p></li>
<li><p>Outputting Transforms</p></li>
<li><p>Used defined transforms</p></li>
</ul></li>
<li><p>Run on multiple execution engines called Runners</p>
<ul>
<li><p>DirectRunner (Local)</p></li>
<li><p>Google Dataflow</p></li>
<li><p>Apache Spark</p></li>
<li><p>Hadoop</p></li>
<li><p>Apache Flink</p></li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>云开发</category>
      </categories>
      <tags>
        <tag>Cloud</tag>
      </tags>
  </entry>
  <entry>
    <title>SWS3004-Lecture 2: Applications and Paradigms</title>
    <url>/2023/08/03/sws3004/lecture2/</url>
    <content><![CDATA[<p>L2 is about Application and Paradigms of Cloud Computing.</p>
<span id="more"></span>
<h2 id="outline">Outline</h2>
<ul>
<li>Cloud Applications
<ul>
<li>Common Features</li>
<li>Applications</li>
<li>Challenges in Developing Applications</li>
<li>Architectural Styles for Cloud Applications</li>
</ul></li>
<li>Cloud Application Development Models
<ul>
<li>Characteristics of Cloud Service Models</li>
<li>Examples of Setting up a Blog</li>
</ul></li>
</ul>
<h2 id="key-terms">Key Terms</h2>
<ol type="1">
<li><p>Divisible workload</p></li>
<li><p>Performance isolation</p></li>
<li><p>Web application architecture layers</p></li>
<li><p>Application development models (IaaS, PaaS, SaaS)</p></li>
</ol>
<h1 id="cloud-applications">Cloud Applications</h1>
<h2 id="common-features-of-cloud-providers">Common Features of Cloud
Providers</h2>
<ul>
<li><p><strong>Basic and higher</strong> - level services (IaaS -&gt;
SaaS).</p></li>
<li><p><strong>Compute and storage resources</strong> - virtual servers
(Linux and Windows) and object store.</p></li>
<li><p><strong>Deployment management services</strong> - load balancer,
auto scaling, message queueing, monitoring, ….</p></li>
<li><p><strong>User interface</strong> - graphical user interface,
command-line interface.</p></li>
</ul>
<h2 id="cloud-applications-1">Cloud Applications</h2>
<ul>
<li>Focus mainly on <strong>enterprise computing</strong>.</li>
<li>Ideally, an application can partition its workload into
<strong>n</strong> segments and spawn <strong>n</strong> instances, and
the execution time reduced by a factor close to <strong>n</strong>.
(<strong>MapReduce</strong>)</li>
<li><strong>Key Challenges</strong>
<ul>
<li><strong>cloud consumer</strong>: scale application to accommodate a
dynamic load, recover after a system failure, efficiently support
checkpoint/restart</li>
<li><strong>cloud provider</strong>: manage a large number of systems
(cloud consumer applications), provides quality of service
guarantee</li>
</ul></li>
<li><strong>Ideal Applications</strong>
<ul>
<li>web services</li>
<li>database services</li>
<li>search services</li>
<li>machine learning with massive-scale models</li>
</ul></li>
<li><strong>Unlikely to perform well</strong>
<ul>
<li>applications with a <strong>complex workflow</strong> and
<strong>multiple dependencies</strong> such as high-performance
computing</li>
<li>applications with <strong>intensive communication</strong> among
concurrent instances</li>
<li>workload <strong>cannot be arbitrarily partitioned</strong></li>
</ul></li>
</ul>
<h2 id="challenges-in-developing-cloud-applications">Challenges in
Developing Cloud Applications</h2>
<ul>
<li><p><strong>Performance isolation</strong> – how to ensure that
customer performance is not affected by other users?</p></li>
<li><p><strong>Reliability</strong> - major concern, server failures
expected when a large number of servers cooperate to compute.</p></li>
<li><p>Cloud infrastructure exhibits <strong>latency</strong> and
<strong>bandwidth</strong> fluctuations which affect the application
performance.</p></li>
<li><p>Performance considerations limit the amount of <em>data
logging</em> (identify unexpected results, errors, monitor application
performance).</p></li>
</ul>
<h2 id="architectural-styles-for-cloud-applications">Architectural
Styles for Cloud Applications</h2>
<ul>
<li><p>Reliance on Internet and web technology (high accessibility, web
browser universality, ease of web-based service development).</p></li>
<li><p>Cloud services use web technology as both the
<strong>implementation medium</strong> and <strong>management
interface</strong>.</p></li>
<li><p>2 basic components of the web are <strong>web browser
client</strong> and <strong>web server</strong>, i.e., based on
<strong>client-server architecture</strong>.</p></li>
</ul>
<p><img src="/images/sws3004-lec2/1.png" alt="3-Tier Web Applications"></p>
<h3 id="as-a-service-cloud-delivery-models">“as-a-Service” Cloud
Delivery Models</h3>
<ol type="1">
<li><p><strong>Simple Object Access Protocol (SOAP) </strong>:
Application protocol for web applications; defines a common web service
messaging format for request and response message exchanges; based on
the XML, uses TCP or UDP transport protocols.</p></li>
<li><p><strong>Representational State Transfer (REST)</strong>: software
architecture for distributed hypermedia systems. Supports client
communication with stateless servers, platform and language independent,
supports data caching, and can be used in the presence of
firewalls.</p></li>
</ol>
<p>Rest is better in simplicity, flexibility, efficiency and
scalability, which is suitable for web applications. SOAP is suitable
for applications requiring higher security, transaction handling, and
reliability, particularly in enterprise-level applications.</p>
<div style="text-align: center;">
<p><img src="/images/sws3004-lec2/2.png" alt="Web Services for Cloud Applications - Example" style="width: 90%; height: 90%; display: block; margin: 0 auto;"></p>
</div>
<h1 id="cloud-application-development-models"><strong>Cloud Application
Development Models</strong></h1>
<h2 id="characteristics-of-cloud-service-models">Characteristics of
Cloud Service Models</h2>
<div style="text-align: center;">
<p><img src="/images/sws3004-lec2/3.png" alt="User and Service Provider Responsibilities in Different Models" style="width: 90%; height: 90%; display: block; margin: 0 auto;"></p>
</div>
<h3 id="infrastructure-as-a-service-for-it-architects">Infrastructure as
a Service (for IT architects)</h3>
<div style="text-align: center;">
<p><img src="/images/sws3004-lec2/4.png" alt="Infrastructure as a Service" style="width: 90%; height: 90%; display: block; margin: 0 auto;"></p>
</div>
<ul>
<li><p>Web access to resources</p></li>
<li><p>Centralized physical resource management</p></li>
<li><p>Elastic services and dynamic scaling</p></li>
<li><p>Shared infrastructure across multiple users</p></li>
<li><p>Preconfigured VMs</p></li>
<li><p>Metered services</p></li>
</ul>
<h3 id="platform-as-a-service-for-developers">Platform as a Service (for
developers)</h3>
<div style="text-align: center;">
<p><img src="/images/sws3004-lec2/5.png" alt="Platform as a Service" style="width: 90%; height: 90%; display: block; margin: 0 auto;"></p>
</div>
<ul>
<li><p>All in one – same IDE to develop, test, deploy, host and maintain
applications</p></li>
<li><p>Web access to development platforms</p></li>
<li><p>Offline access for developers</p></li>
<li><p>Built-in scalability</p></li>
<li><p>Collaborative platform for developers</p></li>
<li><p>Diverse client tools</p></li>
</ul>
<h3 id="software-as-a-service-for-end-users">Software as a Service (for
end users)</h3>
<div style="text-align: center;">
<p><img src="/images/sws3004-lec2/6.png" alt="Software as a Service" style="width: 90%; height: 90%; display: block; margin: 0 auto;"></p>
</div>
<ul>
<li><p><strong>Multi-tenanted</strong> applications</p></li>
<li><p>Web access</p></li>
<li><p>Centralized management of SaaS services</p></li>
<li><p>Multi-device support</p></li>
<li><p>Scalability under varying loads</p></li>
<li><p>High availability</p></li>
<li><p>API integration with other software</p></li>
</ul>
<h2 id="examples-of-setting-up-a-blog">Examples of Setting up a
Blog</h2>
<div style="text-align: center;">
<p><img src="/images/sws3004-lec2/7.png" alt="Examples of Setting up a Blog" style="width: 90%; height: 90%; display: block; margin: 0 auto;"></p>
</div>
<h2 id="bonus-track-function-as-a-service">Bonus Track: Function as a
Service</h2>
<div style="text-align: center;">
<p><img src="/images/sws3004-lec2/8.png" alt="Function as a Service" style="width: 90%; height: 90%; display: block; margin: 0 auto;"></p>
</div>
<div style="text-align: center;">
<p><img src="/images/sws3004-lec2/9.png" alt="Lambda" style="width: 90%; height: 90%; display: block; margin: 0 auto;"></p>
</div>
]]></content>
      <categories>
        <category>云开发</category>
      </categories>
      <tags>
        <tag>Cloud</tag>
      </tags>
  </entry>
  <entry>
    <title>SWS3004-Lecture 1: Concepts and Models</title>
    <url>/2023/07/28/sws3004/lecture1/</url>
    <content><![CDATA[<p>L1 is about Concepts and Models of Cloud Computing.</p>
<span id="more"></span>
<h2 id="outline">Outline</h2>
<ul>
<li>NIST Definition</li>
<li>Cloud Characteristics</li>
<li>Cloud Service(Delivery) Models</li>
<li>Conceptual Reference Architecture</li>
<li>Cloud Deployment Models</li>
<li>Summary</li>
</ul>
<h2 id="key-terms">Key Terms</h2>
<ol type="1">
<li><p>Elasticity</p></li>
<li><p>On-demand self service</p></li>
<li><p>Pay-per-use (measured service)</p></li>
<li><p>Multi-tenancy (location independent resource pooling)</p></li>
<li><p>Cloud service (delivery) models</p></li>
<li><p>Cloud deployment models</p></li>
<li><p>Cloud actors</p></li>
</ol>
<h1 id="definition">Definition</h1>
<p><strong>Cloud</strong> means "smooth" to access, control and measure.
It has <strong>five</strong> essential characteristics,
<strong>four</strong> deployment models and <strong>three</strong>
service models.</p>
<div style="text-align: center;">
<p><img src="/images/sws3004-lec1/1.png" alt="NIST Definition" style="width: 90%; height: 90%; display: block; margin: 0 auto;"></p>
</div>
<h1 id="cloud-characteristics">Cloud Characteristics</h1>
<h2 id="on-demand-self-service-through-a-service-portal">On-demand
self-service through a service portal</h2>
<p>With cloud computing, you can provision computing services, like
server time and network storage, automatically. You won’t need to
interact with the service provider. Cloud customers can access their
cloud accounts through a web self-service portal to view their cloud
services, monitor their usage, and provision and de-provision
services.</p>
<h2 id="broad-network-access-ubiquitous-access">Broad network access
(ubiquitous access)</h2>
<p>Users can access cloud services anytime and anywhere through a
terminal device with network connection. Latency and bandwidth both
count because they affect the quality of service.</p>
<h2 id="location-independent-resource-pooling-multi-tenancy">Location-independent
resource pooling (multi-tenancy)</h2>
<p>Computing resources are gathered together as <strong>pools</strong>,
like CPU pools, memory pools, etc. With resource pooling, multiple
customers can share physical resources using a <strong>multi-tenancy
model</strong>. This model allows customers to share the same
applications or infrastructure while maintaining privacy and security.
It's a fantastic characteristic of cloud, which abstracts and subdivides
physical resources.</p>
<div style="text-align: center;">
<p><img src="/images/sws3004-lec1/3.png" alt="Multi-tenancy" style="width: 80%; height: 80%; display: block; margin: 0 auto;"></p>
</div>
<h2 id="rapid-elasticity-time-to-market-fast-deployment">Rapid
elasticity – time to market / fast deployment</h2>
<p>Cloud services can be elastically provisioned and released, sometimes
automatically, so customers can scale quickly based on demand. With
rapid and unlimited elasticity of cloud service, you don't need to buy
hardware but use cloud resources to satisfy your demand.</p>
<h2 id="measured-service-pay-per-use">Measured service
(pay-per-use)</h2>
<p>In cloud systems, a metering capability optimizes resource usage at a
level of abstraction appropriate to the type of service. For example,
you can use a measured service for storage, processing, bandwidth, and
users. Payment is based on actual consumption by the customer via a
pay-for-what-you-use model. Monitoring, controlling, and reporting
resource use creates a transparent experience for both consumers and
providers of the service.</p>
<h1 id="cloud-servicedelivery-models">Cloud Service(Delivery)
Models</h1>
<p>There are three main models: <strong>SaaS</strong>,
<strong>PaaS</strong> and <strong>IaaS</strong>. As for "steak" service,
IaaS is like providing a kitchen with some pots, PaaS provides raw beef
and pepper additionally, and SaaS provides a plate of steak. More
convenience, but less space to select.</p>
<div style="text-align: center;">
<p><img src="/images/sws3004-lec1/4.png" alt="S/P/IaaS" style="width: 80%; height: 80%; display: block; margin: 0 auto;"></p>
</div>
<div style="text-align: center;">
<p><img src="/images/sws3004-lec1/5.png" alt="Comparison of XaaS" style="width: 80%; height: 80%; display: block; margin: 0 auto;"></p>
</div>
<div style="text-align: center;">
<p><img src="/images/sws3004-lec1/6.png" alt="Pros and Cons of Service Models" style="width: 80%; height: 80%; display: block; margin: 0 auto;"></p>
</div>
<h1 id="conceptual-reference-architecture">Conceptual Reference
Architecture</h1>
<div style="text-align: center;">
<p><img src="/images/sws3004-lec1/7.png" alt="Cloud Computing Reference Architecture" style="width: 80%; height: 80%; display: block; margin: 0 auto;"></p>
</div>
<h2 id="actor-roles">Actor Roles</h2>
<ul>
<li><p><strong>Cloud Consumer</strong> - maintains a business
relationship with, and uses service from <strong>Cloud
Providers</strong>.</p></li>
<li><p><strong>Cloud Provider</strong> – offers a cloud service to cloud
consumers.</p></li>
<li><p><strong>Cloud Auditor</strong> - conducts independent assessment
of cloud services, system operations, performance and security of the
cloud implementation.</p></li>
<li><p><strong>Cloud Broker</strong> - manages the use, performance and
delivery of cloud services, and negotiates relationships between Cloud
Providers and Cloud Consumers.</p></li>
<li><p><strong>Cloud Carrier</strong> - provides connectivity and
transport of cloud services from Cloud Providers to Cloud
Consumers.</p></li>
</ul>
<h1 id="cloud-deployment-models">CLOUD DEPLOYMENT MODELS</h1>
<ul>
<li><strong>Private cloud</strong>
<ul>
<li>solely for used by an organization</li>
<li>for enterprises/corporations with large scale IT</li>
</ul></li>
<li><strong>Public cloud</strong>
<ul>
<li>available to general public, i.e., <strong>shared</strong> by all
consumers</li>
<li>open market for on demand computing and IT resources</li>
<li>concerns: limited SLA, reliability, availability, security,
trust</li>
</ul></li>
<li><strong>Community cloud</strong>
<ul>
<li>shared by several organizations and supporting a specific
community</li>
</ul></li>
<li><strong>Hybrid (federated) cloud</strong>
<ul>
<li>two or more public and private clouds that interoperate</li>
<li>extends private cloud(s) to include a shared public cloud</li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>云开发</category>
      </categories>
      <tags>
        <tag>Cloud</tag>
      </tags>
  </entry>
  <entry>
    <title>SWS3004-Lab Exercise 2</title>
    <url>/2023/07/28/sws3004/lab2/</url>
    <content><![CDATA[<p>This Lab is about Hadoop and Spark, using AWS EMR and S3.</p>
<span id="more"></span>
<h1 id="exercise-2.1">Exercise 2.1</h1>
<blockquote>
<p>Run and compare the execution time of WordCount on Wikipidia’s dump
with both Hadoop MapReduce and Spark. You can use either IaaS or PaaS,
but make sure you use the same type of setup for both Hadoop and Spark
(e.g., if you use EMR for Hadoop MapReduce, then use EMR for Spark
also). You have to use the provided input of size 12 GB. Is there any
difference in the programming model and ease of programming? Is there
any difference in performance? Please explain it in maximum 3
paragraphs. You can include up to 2 performance plots.</p>
<p>Input dataset address on AWS S3:
s3://sws3004-2023/input/enwiki-12GB.xml</p>
<p>You must use this input dataset for both Hadoop MapReduce and
Spark.</p>
<p>(Tip: use the entire address s3://sws3004-2023/input/enwiki-12GB.xml
as parameter to your MapReduce job)</p>
</blockquote>
<h3 id="part-1.-hadoop-mapreduce">Part 1. Hadoop Mapreduce</h3>
<p>First I create a S3 bucket and upload files:</p>
<p><img src="/images/sws3004-lab2/722-1.png" alt="S3 bucket"></p>
<p>Then I create an EMR cluster, select the S3 bucket created in the
previous step as my S3 folder, and select m4.large and default 3
instances as the instance configuration.</p>
<p><img src="/images/sws3004-lab2/722-3.png" alt="EMR"></p>
<p>Now add a step, using <code>WordCount.jar</code> to process the input
from <code>s3://sws3004-2023/input/enwiki-12GB.xml</code>.</p>
<p><img src="/images/sws3004-lab2/722-6.png" alt="EMR Step"></p>
<p>In my S3 bucket, I can check the output when the step finished.</p>
<p><img src="/images/sws3004-lab2/722-9.png" alt="Check the Output"></p>
<p><strong>Hadoop MapReduce performance:</strong> The process takes 42
minutes totally.</p>
<p><img src="/images/sws3004-lab2/722-8.png" alt="Hadoop MapReduce Performance"></p>
<h3 id="part-2.-spark">Part 2. Spark</h3>
<p>I clear the S3 bucket and upload the files of Spark:</p>
<p><img src="/images/sws3004-lab2/722-17.png" alt="Spark"></p>
<p>Then create a new EMR for Spark, and add a step.</p>
<p><img src="/images/sws3004-lab2/722-18.png" alt="EMR Step"></p>
<p><strong>Spark performance:</strong> The process takes 16 minutes
totally.</p>
<p><strong>It seems that Spark is better than Hadoop in performance.
</strong> The reason is Hadoop uses disk to store data while Spark uses
memory to store data, which can reduce the I/O time. Also, MapReduce
requires a lot of time to sort during Shuffle, and sorting seems
inevitable in MapReduce's Shuffle. When Spark is in Shuffle, sorting is
only required for some situations, which is faster.</p>
<h3 id="is-there-any-difference-in-the-programming-model-and-ease-of-programming">Is
there any difference in the programming model and ease of
programming?</h3>
<p><strong>Hadoop MapReduce:</strong> Hadoop MapReduce is a programming
model designed for distributed data processing on large clusters of
commodity hardware. The MapReduce programming model has two steps to
process our data: Map and Reduce.</p>
<ul>
<li><strong>Map:</strong> In the Map phase, the input data is divided
into splits, and each split is processed independently by multiple
mapper tasks in parallel. The mapper tasks extract key-value pairs from
the input data and emit intermediate key-value pairs.</li>
<li><strong>Shuffle and Sort:</strong> The intermediate key-value pairs
emitted by the mappers are shuffled and sorted based on the keys. This
step ensures that all values for the same key are grouped together and
sent to the same reducer task.</li>
<li><strong>Reduce:</strong> In the Reduce phase, the sorted and
shuffled intermediate data is processed by reducer tasks. Each reducer
task processes a subset of the intermediate data, grouped by keys. The
reducer tasks aggregate the values associated with each key and produce
the final output.</li>
</ul>
<p><strong>Spark:</strong> <strong>Spark is a better distributed data
processing engine</strong>, which extends the MapReduce model and offers
more versatility and performance improvements. Spark introduces the
concept of Resilient Distributed Datasets (RDDs), which are the
fundamental data abstraction in Spark. RDDs are distributed collections
of data that can be processed in parallel.</p>
<p>Spark provides a more general programming model compared to Hadoop
MapReduce. It supports not only Map and Reduce operations but also
various other transformations and actions on RDDs, such as filter, join,
groupByKey, reduceByKey and so on. Additionally, Spark offers
specialized libraries like Spark SQL for structured data processing,
Spark Streaming for real-time data streaming, and MLlib for machine
learning tasks.</p>
<p><strong>Difference in Programming Model and Ease of
Programming:</strong></p>
<p>I found a comparison form in Lecture slides:</p>
<p><img src="/images/sws3004-lab2/722-7.jpg" alt="Comparision"></p>
<ol type="1">
<li><strong>Programming Model:</strong>
<ul>
<li>Hadoop MapReduce has a more rigid programming model, where data is
processed in two distinct phases (Map and Reduce), and users need to
explicitly handle intermediate data shuffle and sort.</li>
<li>Spark provides a more flexible and expressive programming model with
RDDs, allowing users to perform complex operations on distributed data
through a wide range of transformations and actions.</li>
</ul></li>
<li><strong>Ease of Programming:</strong>
<ul>
<li>Spark generally offers better ease of programming due to its
high-level APIs and expressive transformations and actions on RDDs. It
simplifies the development of distributed data processing applications,
and its concise syntax often leads to shorter and more readable code
compared to Hadoop MapReduce.</li>
<li>Hadoop MapReduce, being more low-level, might require developers to
write additional code for tasks like intermediate data serialization and
deserialization, which can make the development process more
cumbersome.</li>
</ul></li>
</ol>
<p>In summary, Spark provides a more powerful and user-friendly
programming model compared to Hadoop MapReduce. Spark's RDDs and
higher-level APIs make it easier for developers to write distributed
data processing applications, leading to faster development cycles and
more efficient data processing.</p>
<h1 id="exercise-2.2">Exercise 2.2</h1>
<blockquote>
<p>Write and run on AWS EMR a MapReduce program that computes the total
number of followers and followees for each user in a Twitter dataset.
The dataset is provided to you in the file <em>twitter_combined.txt</em>
taken from http://snap.stanford.edu/data/egonets-Twitter.html. Each line
of this file contains two user ids A and B meaning “<em>User A follows
User B</em>”. For example, the first line is “214328887 34428380” and it
means that “User 214328887 follows User 34428380”.</p>
</blockquote>
<p>My code is below:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// here is the map</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Map</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, IntWritable&gt; {</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text texts, Context context)</span></span><br><span class="line">            <span class="keyword">throws</span> IOException, InterruptedException {</span><br><span class="line">        String[] users = texts.toString().split(<span class="string">" "</span>); <span class="comment">// split as user0 user1</span></span><br><span class="line">        <span class="type">IntWritable</span> <span class="variable">followers</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>(-<span class="number">1</span>); <span class="comment">// negative</span></span><br><span class="line">        <span class="type">IntWritable</span> <span class="variable">follows</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>(<span class="number">1</span>); <span class="comment">// positive</span></span><br><span class="line">        context.write(<span class="keyword">new</span> <span class="title class_">Text</span>(users[<span class="number">1</span>]), followers);</span><br><span class="line">        context.write(<span class="keyword">new</span> <span class="title class_">Text</span>(users[<span class="number">0</span>]), follows);</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// here is the reduce</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Reduce</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable, Text, Text&gt; {</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text texts, Iterable&lt;IntWritable&gt; values, Context context)</span></span><br><span class="line">            <span class="keyword">throws</span> IOException, InterruptedException {</span><br><span class="line">        <span class="type">int</span> <span class="variable">follows</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="type">int</span> <span class="variable">followers</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (IntWritable text : texts) {</span><br><span class="line">            <span class="keyword">if</span> (text.get() &gt; <span class="number">0</span>) {</span><br><span class="line">                follows += text.get();</span><br><span class="line">            } <span class="keyword">else</span> {</span><br><span class="line">                followers -= text.get();</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">// output the result for each user</span></span><br><span class="line">        context.write(texts, <span class="keyword">new</span> <span class="title class_">Text</span>(String.format(<span class="string">"Followers %d"</span>, inDegree)));</span><br><span class="line">        context.write(texts, <span class="keyword">new</span> <span class="title class_">Text</span>(String.format(<span class="string">"Follows %d"</span>, outDegree)));</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure>
<p>Then we create a S3 and upload the files:</p>
<p><img src="/images/sws3004-lab2/722-13.png" alt="S3"></p>
<p>Now we can add a step in EMR and view the final output:</p>
<p><img src="/images/sws3004-lab2/722-15.png" alt="Step"></p>
<p><img src="/images/sws3004-lab2/722-16.png" alt="Result"></p>
<p>So User 214328887 has 628 followers, and follows 951 users.</p>
]]></content>
      <categories>
        <category>云开发</category>
      </categories>
      <tags>
        <tag>Cloud</tag>
        <tag>Lab</tag>
      </tags>
  </entry>
  <entry>
    <title>SWS3004-Lab Exercise 1</title>
    <url>/2023/07/15/sws3004/lab1/</url>
    <content><![CDATA[<p>This Lab is based on Amazon Web Services(AWS)，including EC2, Lambda,
SQS and CloudWatch.</p>
<span id="more"></span>
<h1 id="exercise-1.1">Exercise 1.1</h1>
<h2 id="passwordless-ssh-access-between-two-ec2-instances">Passwordless
SSH access between two EC2 instances</h2>
<blockquote>
<p>Create two (2) AWS EC2 instances (virtual machines) with a
Linux-based operating system(e.g., Ubuntu) and set up
<strong>passwordless</strong> SSH access among them. Let’s suppose we
name those 2 instances A and B. <em>Passwordless</em> SSH means that we
can SSH into instance A from instance B and vice versa without being
asked for a password. How do you do that? Please explain it in 1-2
paragraphs. <strong>[3 marks]</strong></p>
</blockquote>
<p>Firstly, I create two EC2 instances(serverA and serverB) with a
Ubuntu-20.04 OS. The details are shown in Figure 1 and Figure 2 below.
The IPv4 of serverA is 54.174.141.190, and the IPv4 of server B is
44.207.230.223.</p>
<p><img src="/images/sws3004-lab1/714-1.png" alt="Figure 1: Details of EC2 instance A"></p>
<p><img src="/images/sws3004-lab1/714-2.png" alt="Figure 2: Details of EC2 instance B"></p>
<p>Let's start with password-less access from A to B. First, type the
command <code>ssh-keygen -t rsa</code> in instance A. This command will
generate a pair of public/private keys in the
<code>~/.ssh/id_rsa.pub</code> and <code>~/.ssh/id_rsa</code>, shown in
Figure 3.</p>
<p><img src="/images/sws3004-lab1/714-3.png" alt="Figure 3: Generate ssh-key pair"></p>
<p>I met a trouble here: I use command
<code>ssh-copy-id -i ~/.ssh/id_rsa.pub ubuntu@44.207.230.223</code> to
copy the public key of A to the <code>authorized_keys</code> of B, but
it shows Permission denied. The reason for this error is this command
will overwrite the file <code>authorized_keys</code> of B, but this file
is already exists so this command was denied.</p>
<p>Instead, I use <code>cat ~/.ssh/id_rsa.pub</code> in instance A to
display my public key, and use
<code>echo "MY_PUBLIC_KEY" &gt;&gt; ~/.ssh/authorized_keys</code> in
instance B to paste the key. Now type
<code>ssh ubuntu@44.207.230.223</code> in instance A, we can access
instance B successfully, without any password! View relevant screenshot
in Figure 4.</p>
<p><img src="/images/sws3004-lab1/714-4.png" alt="Figure 4: Password-less access from A to B"></p>
<p>Symmetrically, to make instance B to access to A without any
password, just generate ssh-key pair in instance B, and follow the steps
above once again. In Figure 5, both A and B successfully access to each
other, without password.</p>
<p><img src="/images/sws3004-lab1/714-5.png" alt="Figure 5: Password-less SSH access in both directions"></p>
<p>Finally, I summarized the theory of password-less SSH in figure
6.</p>
<p><img src="/images/sws3004-lab1/714-6.png" alt="Figure 6: Theory of Password-less SSH"></p>
<h2 id="password-less-ssh-using-a-different-port">Password-less SSH
using a different port</h2>
<blockquote>
<p>Similar to Exercise 1.1., create two (2) AWS EC2 instances (virtual
machines) with a Linux based operating system (e.g., Ubuntu) and setup
<strong>passwordless</strong> SSH access among them but this time use a
different port for the SSH server (change the default port 22 to port
2222). Do you need to make any other modifications to your EC2
instances? <strong>[4 marks]</strong></p>
</blockquote>
<p>Let's continue on the basis of Exercise 1.1. We have achieved
password-less SSH access in the default port 22, and now we need to
achieve it in port 2222.</p>
<p>First, I edit the security groups of instance A and B, adding a new
rule to allow 2222 port, just like Figure 7 below.</p>
<p><img src="/images/sws3004-lab1/714-7.png" alt="Figure 7: Add a rule in security group"></p>
<p>Then I add Port 2222 in <code>/etc/ssh/sshd_config</code>, shown in
Figure 8.</p>
<center>
<img src="/images/sws3004-lab1/714-8.png" alt="Figure 8: Add Port 2222 in configuration file">
</center>
<p>However, I failed for the first time. How could be? The key is not to
forget to restart the service. Type
<code>sudo service ssh restart</code> to restart service, and then do
password-less SSH access. In figure 9, Instance A and B can
password-less access to each other using Port 2222.</p>
<p><img src="/images/sws3004-lab1/714-9.png" alt="Figure 9: Passworld-less SSH in port 2222"></p>
<h1 id="exercise-1.2">Exercise 1.2</h1>
<h2 id="start-hello-world">Start: Hello World!</h2>
<blockquote>
<p>Start by creating and running a Python AWS hello world using AWS
Management Console, as shown during Lecture 2. Take screenshots of your
Lambda function, test event and the log output to show that the program
runs successfully. Pay attention to setting the role of the Lambda
function to “LabRole”. <strong>[2 marks]</strong></p>
</blockquote>
<p>I create and run a Python AWS hello world using AWS Management
Console, the screenshots of lambda function, test event and the log
output are shown in Figure 10/11/12.</p>
<p><img src="/images/sws3004-lab1/714-10.png" alt="Figure 10: Lambda Function"></p>
<p><img src="/images/sws3004-lab1/714-11.png" alt="Figure 11: Test Event"></p>
<p><img src="/images/sws3004-lab1/714-12.png" alt="Figure 12: Log Output"></p>
<h2 id="create-an-aws-sqs">Create an AWS SQS</h2>
<blockquote>
<p>Create an AWS Simple Queue Service (SQS) Queue and take a screenshot
of the created queue. After creating the queue, note down its Amazon
Resource Name (ARN). <strong>[2 marks]</strong></p>
</blockquote>
<p>Here we create a AWS SQS Queue shown in Figure 13. The ARN is
<code>arn:aws:sqs:us-east-1:368136098362:Queue1</code></p>
<p><img src="/images/sws3004-lab1/714-3.png" alt="Figure 13: AWS SQS Queue"></p>
<h2 id="change-the-code-of-lambda-function">Change the code of Lambda
Function</h2>
<blockquote>
<p>Change the code of your Lambda function such that it returns the
received message from SQS. You are allowed to search on the Internet for
how to do that. Please include the code in your submission(report).
Next, add the created queue (identified by its ARN) as trigger for the
Lambda function. Take a screenshot of the “Function overview Info”
section of your Lambda function. <strong>[2 marks]</strong></p>
</blockquote>
<p>Now we need to change the code of the Lambda function such that it
returns the received message from SQS. The code is shown in the block
below.</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">'Loading function'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">lambda_handler</span>(<span class="params">event, context</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'Received message: %s'</span> % event[<span class="string">'Records'</span>][<span class="number">0</span>][<span class="string">'body'</span>])</span><br><span class="line">    message = event[<span class="string">'Records'</span>][<span class="number">0</span>][<span class="string">'body'</span>]</span><br><span class="line">    <span class="keyword">return</span> message</span><br></pre></td></tr></table></figure>
<p>Then we need to add the created queue (identified by its ARN) as
trigger for the Lambda function. There are two ways here:</p>
<ol type="1">
<li>The first way is add the trigger in AWS Interface, shown in Figure
14.</li>
<li>The second way is to use command line interface, shown in Figure
15.</li>
<li>Two queues are successfully added as trigger, shown in Figure
16.</li>
</ol>
<p><img src="/images/sws3004-lab1/714-14.png" alt="Figure 14: Add queue1 as the trigger of the Lambda function"></p>
<p><img src="/images/sws3004-lab1/714-15.png" alt="Figure 15: Add queue2 as the trigger of the Lambda function"></p>
<p><img src="/images/sws3004-lab1/714-16.png" alt="Figure 16: Two queues are successfully added as trigger"></p>
<p>The Function Overview is shown in Figure 17.</p>
<p><img src="/images/sws3004-lab1/714-17.png" alt="Figure 17: Function Overview"></p>
<h2 id="send-and-receive-message">Send and Receive Message</h2>
<blockquote>
<p>In the SQS dashboard of your queue, click “Send and receive message”,
then send a message with the body “Hello from SWS3004!”. Message Group
ID and Message deduplication ID can be set to 0. Press “Send message”.
Next, go to CloudWatch -&gt; Logs -&gt; Log groups and find the logs for
your Lambda function. Click on the relevant log stream (e.g., the
latest). There should be a message “Hello from SWS3004!” somewhere in
this log stream. Take a screenshot and include it in the report.
<strong>[2 marks]</strong></p>
</blockquote>
<p>We send a message <code>hello:-)</code> from my SQS queue1, and finds
the logs for my function hello, shown as Figure 18 and Figure 19.</p>
<p><img src="/images/sws3004-lab1/714-18.png" alt="Figure 18: Message we send"></p>
<p><img src="/images/sws3004-lab1/714-20.png" alt="Figure 19: Logs"></p>
]]></content>
      <categories>
        <category>云开发</category>
      </categories>
      <tags>
        <tag>Cloud</tag>
        <tag>Lab</tag>
      </tags>
  </entry>
</search>
